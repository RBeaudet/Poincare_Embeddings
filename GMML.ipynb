{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the article on Poincarré Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/charlesdognin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Packages import \n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('wordnet')  \n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But : \n",
    "- Partir d'un mot wordnet.synset(\"mot\")\n",
    "- Construire un dictionnaire représentant le graphe lié à ce mot, du type {\"mot\" : [liste des hyponymes]}\n",
    "- Construire un dictionnaire du type {\"mot\" : niveau du mot}\n",
    "- Construire un dictionnaire des mots embedded du type {\"mot\" : vecteur}\n",
    "\n",
    "Dans le dictionnaire représentant le graphe, un même mot peut être clé ou valeur.\n",
    "Dans le dictionnaire des mots embedded, chaque mot est unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any warm-blooded vertebrate having the skin more or less covered with hair; young are born alive except for the small subclass of monotremes and nourished with milk\n",
      "-------------------------\n",
      "Synset('mammal.n.01')\n"
     ]
    }
   ],
   "source": [
    "# Choose a source word for our graph, here the word \"mammal\", whose level in the graph is 0 (by default)\n",
    "\n",
    "mammal = wordnet.synset(\"mammal.n.01\")\n",
    "print(mammal.definition())  # definition of \"mammal\"\n",
    "print('-------------------------')\n",
    "print(mammal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('female_mammal.n.01'),\n",
       " Synset('fossorial_mammal.n.01'),\n",
       " Synset('metatherian.n.01'),\n",
       " Synset('placental.n.01'),\n",
       " Synset('prototherian.n.01'),\n",
       " Synset('tusker.n.01')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyponyms of the source word, i.e. its direct children in the graph\n",
    "mammal.hyponyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II Training of the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poincarre_Embeddings:\n",
    "    \n",
    "    def __init__(self, epochs, learning_rate, nb_negs, root_node, dimension):\n",
    "        \"\"\"\n",
    "        Object providing the embedding for words related by hypermnemy relations using \n",
    "        hyperbolic geometry.\n",
    "        \n",
    "        Arguments:\n",
    "        \n",
    "        epochs -- number of epochs/iterations\n",
    "        learning_rate -- the learning rate for update of the embedding\n",
    "        nb_negs -- number of negative samples\n",
    "        root_node -- the higher word in the hierarchy, the format must be: wordnet.synset(\"word.n.01\")\n",
    "        dimension -- the embedding dimension\n",
    "        \"\"\"\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.nb_negs = nb_negs\n",
    "        self.root_node = root_node\n",
    "        self.dimension = dimension\n",
    "        \n",
    "    # Sample graph as a dictionnary\n",
    "\n",
    "    def sample_graph(self, root_node, max_level=3) :\n",
    "        \"\"\"\n",
    "        Function that samples a hierarchical network from a root node and its hyponyms.\n",
    "        :param root_node: root node of the network\n",
    "        :param max_level: (int) maximum level of the network\n",
    "        :return graph: dictionnary representing the graph {\"node\" : [hyponyms]}\n",
    "        :return levels: dictionnary representing the level of each node {\"node\" : level}\n",
    "        \"\"\"\n",
    "\n",
    "        graph = {}\n",
    "\n",
    "        # keep track of visited nodes\n",
    "        explored = []\n",
    "\n",
    "        # keep track of nodes to be checked\n",
    "        queue = [root_node]\n",
    "\n",
    "        levels = {}\n",
    "        levels[str(root_node)] = 0\n",
    "\n",
    "        visited = [str(root_node)]\n",
    "\n",
    "        while queue:\n",
    "\n",
    "            # take out first node from queue\n",
    "            node = queue.pop(0)  # node n'est PAS un str\n",
    "\n",
    "            # condition on maximum level\n",
    "            if levels[str(node)] == max_level:\n",
    "                graph[str(node)] = []\n",
    "                break;\n",
    "\n",
    "            # mark node as explored node\n",
    "            explored.append(str(node))  # explored est un str\n",
    "\n",
    "            # sample neighbours of node (i.e. its hyponyms)\n",
    "            neighbours = [neighbour for neighbour in node.hyponyms()]  # ce sont pas des str\n",
    "            neighbours_str = [str(neighbour) for neighbour in node.hyponyms()]\n",
    "\n",
    "            # add neighbours to the graph (as children of the node)\n",
    "            graph[str(node)] = neighbours_str\n",
    "\n",
    "            # add neighbours of node to queue\n",
    "            for neighbour in neighbours :   # no str\n",
    "                if str(neighbour) not in visited :\n",
    "                    queue.append(neighbour) # no str\n",
    "                    visited.append(str(neighbour))\n",
    "                    levels[str(neighbour)] = levels[str(node)] + 1\n",
    "\n",
    "        return graph, levels\n",
    "    \n",
    "    def sample_embeddings(self, graph, dimension):\n",
    "        \"\"\"\n",
    "        Initializes embedded vectors of graph.\n",
    "        :param graph: graph containing words\n",
    "        :param dimension: (int) dimension of the embedding space\n",
    "        :return embeddings: dictionnary of the form {\"node\" : vector}\n",
    "        \"\"\"\n",
    "\n",
    "        embeddings = {}\n",
    "\n",
    "        for word in graph:\n",
    "            embeddings[word] = np.random.uniform(low=-0.1, high=0.1, size=(dimension,))\n",
    "\n",
    "        return embeddings\n",
    "    \n",
    "    def create_embeddings(self, dimension, root_node):\n",
    "        \"\"\"\n",
    "        Creates embeddings for words\n",
    "        \"\"\"\n",
    "        graph, levels = self.sample_graph(self.root_node) \n",
    "        embeddings = self.sample_embeddings(graph, self.dimension)\n",
    "        \n",
    "        return graph, embeddings\n",
    "        \n",
    "\n",
    "    def dist(self, u, v):\n",
    "        \"\"\"\n",
    "        Computes the distance for the Poincaré disk model between two vectors u and v\n",
    "\n",
    "        Arguments:\n",
    "        u -- first embedded object\n",
    "        v -- second embedded object\n",
    "\n",
    "        Returns:\n",
    "        z -- the ditance between the two objects\n",
    "        \"\"\"\n",
    "\n",
    "        norm2u = norm(u)**2\n",
    "        norm2v = norm(u)**2\n",
    "        norm2distuv = norm(u - v)**2\n",
    "        t = 1 + 2 * (norm2distuv / ((1 - norm2u) * (1 - norm2v)))\n",
    "        z = np.arccosh(t)\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def pdr(self, theta, x):\n",
    "        \"\"\"\n",
    "        Computes the partial derivative w.r.t theta\n",
    "\n",
    "        Arguments:\n",
    "        theta -- embedding of the object\n",
    "        x -- vector corresponding to the embedding of another object (same dimension as theta)\n",
    "\n",
    "        Returns:\n",
    "        partial -- the derivative (same dimension as theta)  \n",
    "        \"\"\"\n",
    "\n",
    "        alpha = 1.0 - norm(theta)**2\n",
    "        assert len(alpha.shape) == 0\n",
    "        beta = 1.0 - norm(x)**2\n",
    "        assert len(beta.shape) == 0\n",
    "        gamma = 1 + (2 / (alpha * beta)) * norm(alpha - x)**2\n",
    "        assert len(gamma.shape) == 0\n",
    "        assert gamma**2 - 1 >= 0\n",
    "        partial = 4.0 / (beta * np.sqrt(gamma**2 - 1)) * (((norm(x) - 2 * np.dot(theta, x) + 1) / alpha**2) * theta - (x / alpha))\n",
    "\n",
    "        return partial\n",
    "\n",
    "    def proj(self, theta, epsilon=1e-5):\n",
    "        \"\"\"\n",
    "        Projection in the Poincaré disk ball\n",
    "\n",
    "        Parameters:\n",
    "        theta --  embedding of the object\n",
    "        epsilon -- scalar (for stability)\n",
    "\n",
    "        Returns:\n",
    "        theta -- after projection\n",
    "        \"\"\"\n",
    "\n",
    "        if norm(theta) >= 1:\n",
    "            theta = (theta / norm(theta)) - epsilon\n",
    "\n",
    "        return theta\n",
    "\n",
    "    def update(self, theta, grad, learning_rate):\n",
    "        \"\"\"\n",
    "        Computes the full update for a single embedding of theta\n",
    "\n",
    "        Parameters:\n",
    "        theta -- current embedding of the object\n",
    "        grad -- gradient of the loss function \n",
    "        learning_rate -- the learning rate \n",
    "\n",
    "        Returns:\n",
    "        theta -- the updated theta\n",
    "        \"\"\"\n",
    "\n",
    "        upd = (learning_rate / 4) * (1 - norm(theta)**2)**2 * grad\n",
    "        theta = self.proj(theta - upd)\n",
    "        assert theta.shape == upd.shape\n",
    "\n",
    "        return theta\n",
    "    \n",
    "    def loss(self, u, v, negative_samples):\n",
    "        \"\"\"\n",
    "        Computes the loss for a single couple of related nodes (u,v)\n",
    "\n",
    "        Arguments:\n",
    "        u -- embedding of one object\n",
    "        v -- embedding of one object\n",
    "        negative_samples -- set of negative samples for u including v\n",
    "\n",
    "        Returns:\n",
    "        loss -- the value of the loss\n",
    "        \"\"\"\n",
    "        negative_distances = [np.exp(-self.dist(u, k)) for k in negative_samples]\n",
    "        loss = -self.dist(u, v) - np.log(np.sum(negative_distances))\n",
    "\n",
    "        return loss \n",
    "    \n",
    "    def pdl(self, u, negative_samples):\n",
    "        \"\"\"\n",
    "        Computes the partial derivative of the loss w.r.t d(u,v), d(u,v'), where v' is a negative example for u\n",
    "        \n",
    "        Arguments:\n",
    "        u -- embedding of one object\n",
    "        negative_samples -- list of negative samples for u\n",
    "        positive -- boolean, computes the partial derivative of the loss w.r.t d(u,v) if True\n",
    "        \n",
    "        Returns:\n",
    "        derivative -- the partial derivative (scalar or list)\n",
    "        \"\"\"\n",
    "    \n",
    "        negative_distances = [np.exp(-self.dist(u, k)) for k in negative_samples]\n",
    "        derivative = [np.exp(self.dist(u, k)) / np.sum(negative_distances) for k in negative_samples]\n",
    "\n",
    "        return derivative \n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_word(word):\n",
    "        word = str(word).strip(\"Synset\")\n",
    "        word = word.strip(\"(\")\n",
    "        word = word.strip(\")\")\n",
    "        word = word.strip(\"'\")\n",
    "        word = word.strip(\".n.01\")\n",
    "        return word\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        graph, embeddings = self.create_embeddings(self.dimension, self.root_node)\n",
    "        embeddings_temp = embeddings.copy()\n",
    "        \n",
    "        ## Select couple (u, v) and negative samples for u\n",
    "        for u in embeddings_temp:\n",
    "            if len(graph[u]) == 0:\n",
    "                continue\n",
    "            \n",
    "            for v in graph[u]:\n",
    "                if v not in graph.keys():\n",
    "                    graph[v] = []\n",
    "                    embeddings[v] = np.random.uniform(low=-0.1, high=0.1, size=(self.dimension,))\n",
    "                \n",
    "        for epoch in range(self.epochs):\n",
    "            if epoch % 10 == 0:\n",
    "                print(epoch)\n",
    "\n",
    "            # Select word\n",
    "            for u in embeddings:\n",
    "                if len(graph[u]) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Select v among the hyponyms of u\n",
    "                v = np.random.choice(graph[u])\n",
    "                #if v not in graph.keys():\n",
    "                    #graph[v] = []\n",
    "                    #embeddings[v] = np.random.uniform(low=-0.001, high=0.001, size=(self.dimension,))\n",
    "                \n",
    "                # Select negative examples for u\n",
    "                negative_samples, negative_samples_words = [], []  # list of vectors/list of words\n",
    "                \n",
    "                while len(negative_samples) < self.nb_negs:\n",
    "\n",
    "                    # draw sample randomly from data\n",
    "                    negative_sample = np.random.choice(list(embeddings.keys()))\n",
    "\n",
    "                    # if the drawn sample is connected to u, discard it\n",
    "                    if negative_sample in graph[u] or u in graph[negative_sample] or negative_sample == u:\n",
    "                        continue \n",
    "\n",
    "                    negative_samples_words.append(negative_sample)\n",
    "                    negative_sample = embeddings[negative_sample]\n",
    "                    negative_samples.append(negative_sample)\n",
    "\n",
    "\n",
    "                ## Compute the individual loss\n",
    "                loss = self.loss(embeddings[u], embeddings[v], negative_samples)\n",
    "\n",
    "                ## Compute the partial derivatives of the loss with respect to u, v and the negative examples\n",
    "\n",
    "                # derivative of loss with respect to u\n",
    "                grad_u = -1.0 * self.pdr(embeddings[u], embeddings[v])\n",
    "\n",
    "                # derivative of loss with respect to v\n",
    "                grad_v = -1.0 * self.pdr(embeddings[v], embeddings[u])\n",
    "\n",
    "                # derivative of loss with respect to the negative examples\n",
    "                grad_negatives = []\n",
    "                grad_negatives_temp = self.pdl(embeddings[u], negative_samples)\n",
    "\n",
    "                for (negative_sample, grad_negative) in zip(negative_samples, grad_negatives_temp):\n",
    "                    gradient = grad_negative * self.pdr(negative_sample, embeddings[u])\n",
    "                    grad_negatives.append(gradient)\n",
    "\n",
    "                ## Update embeddings\n",
    "\n",
    "                # update u\n",
    "                embeddings[u] = self.update(embeddings[u], grad_u, self.learning_rate)\n",
    "\n",
    "                # update v\n",
    "                embeddings[v] = self.update(embeddings[v], grad_v, self.learning_rate)\n",
    "\n",
    "                # update negative samples\n",
    "                for (negative_sample, grad_negative, negative_sample_word) in zip(negative_samples, grad_negatives, negative_samples_words):\n",
    "                        embeddings[negative_sample_word] = self.update(negative_sample, grad_negative, self.learning_rate)\n",
    "                                           \n",
    "        test = [embeddings[u] for u in embeddings]\n",
    "        #return test\n",
    "        return embeddings\n",
    "        \n",
    "    def plot_(self, embeddings):\n",
    "        \"\"\"\n",
    "        Function that allows to plot the embedded vectors when the embedding space is 2 dimensional\n",
    "        \"\"\"\n",
    "\n",
    "        fig = plt.figure()\n",
    "        \n",
    "        fig, ax = plt.subplots();\n",
    "         \n",
    "        for word in np.random.choice(list(embeddings.keys()), 10):\n",
    "            ax.scatter(embeddings[word][0], embeddings[word][1])\n",
    "            ax.annotate(clean_word(word), (embeddings[word][0], embeddings[word][1]))\n",
    "        ax.scatter(embeddings[\"Synset('mammal.n.01')\"][0], embeddings[\"Synset('mammal.n.01')\"][1])\n",
    "        ax.annotate(clean_word(\"Synset('mammal.n.01')\"), (embeddings[\"Synset('mammal.n.01')\"][0], embeddings[\"Synset('mammal.n.01')\"][1]))\n",
    "        print(embeddings[\"Synset('mammal.n.01')\"])\n",
    "        plt.show();\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "[0.98633569 0.16467811]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3441ce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAD8CAYAAAA2T650AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDWNQ/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a33654048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mammal = wordnet.synset(\"mammal.n.01\")\n",
    "cls = Poincarre_Embeddings(2000, 0.01, 4, mammal, 2)\n",
    "embeddings = cls.train()\n",
    "cls.plot_(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
